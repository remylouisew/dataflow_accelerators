{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8a5fff-15a7-4fbd-9f88-322771633081",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.0/nvvm/libdevice\n",
      "/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n"
     ]
    }
   ],
   "source": [
    "!find /usr/local/cuda-* -iname 'libdevice'\n",
    "!find /usr/local/cuda-* -iname 'libnvvm.so'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3109d894-6dbe-4fa6-b368-3e36e0d84756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in /jupyter/.kernels/apache-beam-2.56.0/lib/python3.10/site-packages (from numba) (1.26.4)\n",
      "Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numba\n",
    "\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c2066ad-d959-4fac-b777-03148ac8d9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "import tensorflow as tf\n",
    "\n",
    "from numba import cuda, njit\n",
    "\n",
    "@cuda.jit\n",
    "def check_gpus(_: None, gpus_optional: bool = False) -> None:\n",
    "    \"\"\"Validates that we are detecting GPUs, otherwise raise a RuntimeError.\"\"\"\n",
    "    gpu_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    if gpu_devices:\n",
    "        logging.info(f\"Using GPU: {gpu_devices}\")\n",
    "    elif gpus_optional:\n",
    "        logging.warning(\"No GPUs found, defaulting to CPU.\")\n",
    "    else:\n",
    "        raise RuntimeError(\"No GPUs found.\")\n",
    "\n",
    "@cuda.jit\n",
    "def run(input_text: str, beam_args: list[str] | None = None) -> None:\n",
    "    beam_options = PipelineOptions(direct_num_workers=0,  # default threads/subprocess to the number of cores on this machine\n",
    "    direct_running_mode='multi_threading')\n",
    "    pipeline = beam.Pipeline(InteractiveRunner(), options=beam_options)\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Create data\" >> beam.Create([input_text])\n",
    "        | \"Check GPU availability\"\n",
    "        >> beam.Map(\n",
    "            lambda x, unused_side_input: x,\n",
    "            unused_side_input=beam.pvalue.AsSingleton(\n",
    "                pipeline | beam.Create([None]) | beam.Map(check_gpus)\n",
    "            ),\n",
    "        )\n",
    "        | \"My transform\" >> beam.Map(logging.info)\n",
    "    )\n",
    "    pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae571ad1-582f-49df-a220-e61b86d5a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'cool-machine-learning'\n",
    "_REGION = 'us-central1'\n",
    "_JOB_NAME = 'test1'\n",
    "_TEMP_LOCATION = 'rw-cool-test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e96185d-d8d8-41b6-8039-4b800d46706b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = \" --runner=DataflowRunner --project=$PROJECT_ID --region=$_REGION --job_name=$_JOB_NAME --temp_location=$_TEMP_LOCATION \\\n",
    " --machine_type=n1-standard-4 \\\n",
    " --experiment=worker_accelerator=type:$_GPU_TYPE;count:$_GPU_COUNT;install-nvidia-driver \\\n",
    " --experiment=use_runner_v2 --experiment=no_use_multiple_sdk_containers --disk_size_gb=50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da15df2d-e538-4b8a-bfb5-22e6f2d4edb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m logging\u001b[38;5;241m.\u001b[39mgetLogger()\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/jupyter/.kernels/apache-beam-2.56.0/lib/python3.10/site-packages/numba/cuda/dispatcher.py:672\u001b[0m, in \u001b[0;36mCUDADispatcher.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m# An attempt to launch an unconfigured kernel\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(missing_launch_config_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: \nKernel launch configuration was not specified. Use the syntax:\n\nkernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n\nSee https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "run('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbb938-88f1-4419-80f6-47d03529ef1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "apache-beam-2.56.0",
   "name": ".m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m124"
  },
  "kernelspec": {
   "display_name": "Apache Beam 2.56.0 (Local)",
   "language": "python",
   "name": "apache-beam-2.56.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
